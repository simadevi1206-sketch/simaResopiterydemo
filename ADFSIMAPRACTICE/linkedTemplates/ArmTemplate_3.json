{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "ADFSIMAPRACTICE"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/pl for store p pl details n lookup also we can use')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Copy data",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "JsonSource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": true,
									"enablePartitionDiscovery": false
								},
								"formatSettings": {
									"type": "JsonReadSettings"
								}
							},
							"sink": {
								"type": "DelimitedTextSink",
								"storeSettings": {
									"type": "AzureBlobStorageWriteSettings"
								},
								"formatSettings": {
									"type": "DelimitedTextWriteSettings",
									"quoteAllText": true,
									"fileExtension": ".txt"
								}
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"mappings": [
									{
										"source": {
											"path": "$['EmployeeID']"
										},
										"sink": {
											"name": "EmployeeID"
										}
									},
									{
										"source": {
											"path": "$['EmployeeName']"
										},
										"sink": {
											"name": "EmployeeName"
										}
									},
									{
										"source": {
											"path": "$['Department']"
										},
										"sink": {
											"name": "Department"
										}
									},
									{
										"source": {
											"path": "$['Salary']"
										},
										"sink": {
											"name": "Salary"
										}
									},
									{
										"source": {
											"path": "$['DateOfJoining']"
										},
										"sink": {
											"name": "DateOfJoining"
										}
									}
								]
							}
						},
						"inputs": [
							{
								"referenceName": "source",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "sink_csv",
								"type": "DatasetReference",
								"parameters": {
									"folder": {
										"value": "@pipeline().parameters.foldername",
										"type": "Expression"
									},
									"filename": {
										"value": "@pipeline().parameters.filename",
										"type": "Expression"
									}
								}
							}
						]
					},
					{
						"name": "Stored procedure for pl details",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "Copy data",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[[dbo].[sp_logpipelineExecutionDetails]",
							"storedProcedureParameters": {
								"DataFacroryName": {
									"value": "",
									"type": "String"
								},
								"PipelineName": {
									"value": "",
									"type": "String"
								},
								"PipelineRunId": {
									"value": "",
									"type": "String"
								},
								"PipelineTriggerId": {
									"value": "",
									"type": "String"
								},
								"PipelineTriggerName": {
									"value": "",
									"type": "String"
								}
							}
						},
						"linkedServiceName": {
							"referenceName": "linkedserviceforSQLserver",
							"type": "LinkedServiceReference"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"foldername": {
						"type": "string"
					},
					"filename": {
						"type": "string"
					}
				},
				"annotations": [],
				"lastPublishTime": "2025-11-23T16:44:36Z"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/test store procedure')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Copy data",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "JsonSource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": true,
									"enablePartitionDiscovery": false
								},
								"formatSettings": {
									"type": "JsonReadSettings"
								}
							},
							"sink": {
								"type": "DelimitedTextSink",
								"storeSettings": {
									"type": "AzureBlobStorageWriteSettings"
								},
								"formatSettings": {
									"type": "DelimitedTextWriteSettings",
									"quoteAllText": true,
									"fileExtension": ".txt"
								}
							},
							"enableStaging": false
						},
						"inputs": [
							{
								"referenceName": "source",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "sink_csv",
								"type": "DatasetReference",
								"parameters": {
									"folder": {
										"value": "@pipeline().parameters.folder",
										"type": "Expression"
									},
									"filename": {
										"value": "@pipeline().parameters.file",
										"type": "Expression"
									}
								}
							}
						]
					},
					{
						"name": "Stored procedure",
						"type": "SqlServerStoredProcedure",
						"dependsOn": [
							{
								"activity": "Copy data",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"storedProcedureName": "[[dbo].[sp_logpipelineExecutionDetails]",
							"storedProcedureParameters": {
								"DataFacroryName": {
									"value": "",
									"type": "String"
								},
								"PipelineName": {
									"value": "",
									"type": "String"
								},
								"PipelineRunId": {
									"value": "",
									"type": "String"
								},
								"PipelineTriggerId": {
									"value": "",
									"type": "String"
								},
								"PipelineTriggerName": {
									"value": "",
									"type": "String"
								}
							}
						},
						"linkedServiceName": {
							"referenceName": "linkedserviceforSQLserver",
							"type": "LinkedServiceReference"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"parameters": {
					"folder": {
						"type": "string"
					},
					"file": {
						"type": "string"
					}
				},
				"annotations": [],
				"lastPublishTime": "2025-11-23T17:24:44Z"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/sqloutputsalesproductcategory')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "linkedserviceforSQLserver",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "SqlServerTable",
				"schema": [
					{
						"name": "ProductCategoryID",
						"type": "int",
						"precision": 10
					},
					{
						"name": "ParentProductCategoryID",
						"type": "int",
						"precision": 10
					},
					{
						"name": "Name",
						"type": "nvarchar"
					},
					{
						"name": "rowguid",
						"type": "uniqueidentifier"
					},
					{
						"name": "ModifiedDate",
						"type": "datetime",
						"precision": 23,
						"scale": 3
					}
				],
				"typeProperties": {
					"schema": "SalesLT",
					"table": "ProductCategory"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Aggregation')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "inputDatasetForAggregation",
								"type": "DatasetReference"
							},
							"name": "employee"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "SinkDatasetforAggregation",
								"type": "DatasetReference"
							},
							"name": "sink",
							"rejectedDataLinkedService": {
								"referenceName": "AzureBlobStorage1",
								"type": "LinkedServiceReference"
							}
						}
					],
					"transformations": [
						{
							"name": "aggregate"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Name as string,",
						"          DepartmentID as short,",
						"          DepartmentName as string,",
						"          DateOfJoining as date,",
						"          employeeID as short",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> employee",
						"employee aggregate(groupBy(DepartmentID),",
						"     {Total Number of employees} = count(employeeID),",
						"     partitionBy('hash', 1)) ~> aggregate",
						"aggregate sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Aggregation.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Cache Sink')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "inputDatasetForAggregation",
								"type": "DatasetReference"
							},
							"name": "employee"
						}
					],
					"sinks": [
						{
							"name": "sink"
						}
					],
					"transformations": [
						{
							"name": "aggregate"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Name as string,",
						"          DepartmentID as string,",
						"          DateOfJoining as string,",
						"          employeeID as string,",
						"          Salary as string,",
						"          DepartmentName as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> employee",
						"employee aggregate(MaxSalary = max(toInteger(Salary)),",
						"     partitionBy('hash', 1)) ~> aggregate",
						"aggregate sink(validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     store: 'cache',",
						"     format: 'inline',",
						"     output: true,",
						"     saveOrder: 1) ~> sink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/DataFlow3')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Real Time Scenario Data"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "AzureSql",
								"type": "DatasetReference"
							},
							"name": "source"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Sinksource",
								"type": "DatasetReference"
							},
							"name": "sink"
						}
					],
					"transformations": [
						{
							"name": "filter"
						}
					],
					"scriptLines": [
						"source(output(",
						"          SalesOrderID as integer,",
						"          SalesOrderDetailID as integer,",
						"          OrderQty as short,",
						"          ProductID as integer,",
						"          UnitPrice as decimal(19,4),",
						"          UnitPriceDiscount as decimal(19,4),",
						"          LineTotal as decimal(38,6),",
						"          rowguid as string,",
						"          ModifiedDate as timestamp",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table',",
						"     partitionBy('hash', 1)) ~> source",
						"source filter(UnitPrice<500,",
						"     partitionBy('hash', 1)) ~> filter",
						"filter sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Error Handling Dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Real Time Scenario Data"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "inputDatasetForAggregation",
								"type": "DatasetReference"
							},
							"name": "employee"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "inputDatasetForAggregation",
								"type": "DatasetReference"
							},
							"name": "sink",
							"rejectedDataLinkedService": {
								"referenceName": "AzureBlobStorage1",
								"type": "LinkedServiceReference"
							}
						},
						{
							"dataset": {
								"referenceName": "inputDatasetForAggregation",
								"type": "DatasetReference"
							},
							"name": "sink2",
							"rejectedDataLinkedService": {
								"referenceName": "AzureBlobStorage1",
								"type": "LinkedServiceReference"
							}
						}
					],
					"transformations": [
						{
							"name": "conditionalsplit1"
						},
						{
							"name": "derivedColumnforErrorRows"
						},
						{
							"name": "derivedforGoodRows"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Name as string,",
						"          DepartmentID as string,",
						"          DateOfJoining as string,",
						"          employeeID as string,",
						"          Salary as string,",
						"          DepartmentName as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employee",
						"employee split(isNull(toDate(DateOfJoining)),",
						"     disjoint: false,",
						"     partitionBy('hash', 1)) ~> conditionalsplit1@(errorRows, GoodRows)",
						"conditionalsplit1@errorRows derive(FileName = \"employee_data.txt\") ~> derivedColumnforErrorRows",
						"conditionalsplit1@GoodRows derive(fileName = \"employee_data.txt\",",
						"     partitionBy('hash', 1)) ~> derivedforGoodRows",
						"derivedColumnforErrorRows sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Name as string,",
						"          DepartmentID as string,",
						"          DateOfJoining as string,",
						"          employeeID as string,",
						"          Salary as string,",
						"          DepartmentName as string",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink",
						"derivedforGoodRows sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Name as string,",
						"          DepartmentID as string,",
						"          DateOfJoining as string,",
						"          employeeID as string,",
						"          Salary as string,",
						"          DepartmentName as string",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink2"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Exist dataFlow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "employee1csvsamebutfewextrarowadd",
								"type": "DatasetReference"
							},
							"name": "Employee"
						},
						{
							"dataset": {
								"referenceName": "joinsinputdepartment",
								"type": "DatasetReference"
							},
							"name": "department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Sinksource",
								"type": "DatasetReference"
							},
							"name": "sink",
							"rejectedDataLinkedService": {
								"referenceName": "AzureBlobStorage1",
								"type": "LinkedServiceReference"
							}
						}
					],
					"transformations": [
						{
							"name": "exists"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Name as string,",
						"          DepartmentID as string,",
						"          DateOfJoining as date,",
						"          employeeID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> Employee",
						"source(output(",
						"          DepartmentID as string,",
						"          DepartmentName as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> department",
						"Employee, department exists(employeeID == department@DepartmentID,",
						"     negate:false,",
						"     partitionBy('hash', 1),",
						"     broadcast: 'auto')~> exists",
						"exists sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Exist.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Lookup_Dataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "employee1csvsamebutfewextrarowadd",
								"type": "DatasetReference"
							},
							"name": "employee"
						},
						{
							"dataset": {
								"referenceName": "joinsinputdepartment",
								"type": "DatasetReference"
							},
							"name": "department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Sinksource",
								"type": "DatasetReference"
							},
							"name": "sink",
							"rejectedDataLinkedService": {
								"referenceName": "AzureBlobStorage1",
								"type": "LinkedServiceReference"
							}
						}
					],
					"transformations": [
						{
							"name": "lookup"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Name as string,",
						"          DepartmentID as string,",
						"          DateOfJoining as date,",
						"          employeeID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employee",
						"source(output(",
						"          DepartmentID as string,",
						"          DepartmentName as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> department",
						"employee, department lookup(employee@DepartmentID == department@DepartmentID,",
						"     multiple: false,",
						"     pickup: 'any',",
						"     partitionBy('hash', 1),",
						"     broadcast: 'auto')~> lookup",
						"lookup sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['LookupDataflow_csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/NotExist')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "employee1csvsamebutfewextrarowadd",
								"type": "DatasetReference"
							},
							"name": "employee"
						},
						{
							"dataset": {
								"referenceName": "joinsinputdepartment",
								"type": "DatasetReference"
							},
							"name": "department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Sinksource",
								"type": "DatasetReference"
							},
							"name": "sink",
							"rejectedDataLinkedService": {
								"referenceName": "AzureBlobStorage1",
								"type": "LinkedServiceReference"
							}
						}
					],
					"transformations": [
						{
							"name": "exists"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Name as string,",
						"          DepartmentID as string,",
						"          DateOfJoining as date,",
						"          employeeID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employee",
						"source(output(",
						"          DepartmentID as string,",
						"          DepartmentName as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> department",
						"employee, department exists(employee@DepartmentID == department@DepartmentID,",
						"     negate:true,",
						"     partitionBy('hash', 1),",
						"     broadcast: 'auto')~> exists",
						"exists sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['NotExist.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          Name,",
						"          DepartmentID,",
						"          DateOfJoining,",
						"          employeeID",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/ParameterDataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "inputDatasetForAggregation",
								"type": "DatasetReference"
							},
							"name": "employee"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Sinksource",
								"type": "DatasetReference"
							},
							"name": "Sink"
						}
					],
					"transformations": [
						{
							"name": "filter"
						}
					],
					"scriptLines": [
						"parameters{",
						"     deptName as string",
						"}",
						"source(output(",
						"          Name as string,",
						"          DepartmentID as integer,",
						"          DateOfJoining as date,",
						"          employeeID as integer,",
						"          Salary as integer,",
						"          DepartmentName as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> employee",
						"employee filter(DepartmentName==$deptName,",
						"     partitionBy('hash', 1)) ~> filter",
						"filter sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['ParameterDataFlow.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          Name,",
						"          DepartmentID,",
						"          DateOfJoining,",
						"          employeeID,",
						"          Salary,",
						"          DepartmentName",
						"     ),",
						"     partitionBy('hash', 1)) ~> Sink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/RankDataFlow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "inputDatasetForAggregation",
								"type": "DatasetReference"
							},
							"name": "employee"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Sinksource",
								"type": "DatasetReference"
							},
							"name": "sink",
							"rejectedDataLinkedService": {
								"referenceName": "AzureBlobStorage1",
								"type": "LinkedServiceReference"
							}
						}
					],
					"transformations": [
						{
							"name": "rank"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Name as string,",
						"          DepartmentID as string,",
						"          DateOfJoining as date,",
						"          employeeID as string,",
						"          Salary as string,",
						"          DepartmentName as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> employee",
						"employee rank(asc(Salary, true),",
						"     output(Ranking as long),",
						"     partitionBy('hash', 1)) ~> rank",
						"rank sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['RankingDataflow.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/RunningTotal')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Real Time Scenario Data"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Runningtotal",
								"type": "DatasetReference"
							},
							"name": "employeerunning"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Sinksource",
								"type": "DatasetReference"
							},
							"name": "sink",
							"rejectedDataLinkedService": {
								"referenceName": "AzureBlobStorage1",
								"type": "LinkedServiceReference"
							}
						}
					],
					"transformations": [
						{
							"name": "window"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EmployeeID as short,",
						"          EmployeeName as string,",
						"          DepartmentID as string,",
						"          DateOfJoining as date,",
						"          Salary as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employeerunning",
						"employeerunning window(asc(Salary, true),",
						"     {Running Total} = sum(toInteger(Salary)),",
						"     partitionBy('hash', 1)) ~> window",
						"window sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/SelectDataFlow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "inputDatasetForAggregation",
								"type": "DatasetReference"
							},
							"name": "source"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Sinksource",
								"type": "DatasetReference"
							},
							"name": "sink",
							"rejectedDataLinkedService": {
								"referenceName": "AzureBlobStorage1",
								"type": "LinkedServiceReference"
							}
						}
					],
					"transformations": [
						{
							"name": "select"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Name as string,",
						"          DepartmentID as string,",
						"          DateOfJoining as date,",
						"          employeeID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source",
						"source select(mapColumn(",
						"          Name,",
						"          DepartmentID,",
						"          DateOfJoining,",
						"          employeeID",
						"     ),",
						"     partitionBy('hash', 1),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select",
						"select sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['SelectDataflow.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Surrogate')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "joinsinputdepartment",
								"type": "DatasetReference"
							},
							"name": "department"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Sinksource",
								"type": "DatasetReference"
							},
							"name": "sink",
							"rejectedDataLinkedService": {
								"referenceName": "AzureBlobStorage1",
								"type": "LinkedServiceReference"
							}
						}
					],
					"transformations": [
						{
							"name": "surrogateKey"
						}
					],
					"scriptLines": [
						"source(output(",
						"          DepartmentID as string,",
						"          DepartmentName as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> department",
						"department keyGenerate(output(DepartmentKey as long),",
						"     startAt: 1L,",
						"     stepValue: 1L,",
						"     partitionBy('hash', 1)) ~> surrogateKey",
						"surrogateKey sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Union')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "UnionHR",
								"type": "DatasetReference"
							},
							"name": "HR"
						},
						{
							"dataset": {
								"referenceName": "UnionIT",
								"type": "DatasetReference"
							},
							"name": "IT"
						},
						{
							"dataset": {
								"referenceName": "UnionPayRoll",
								"type": "DatasetReference"
							},
							"name": "PayRoll"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Sinksource",
								"type": "DatasetReference"
							},
							"name": "sink",
							"rejectedDataLinkedService": {
								"referenceName": "AzureBlobStorage1",
								"type": "LinkedServiceReference"
							}
						}
					],
					"transformations": [
						{
							"name": "union"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Name as string,",
						"          DepartmentID as string,",
						"          DateOfJoining as date,",
						"          employeeID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> HR",
						"source(output(",
						"          Name as string,",
						"          DepartmentID as string,",
						"          DateOfJoining as date,",
						"          employeeID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> IT",
						"source(output(",
						"          Name as string,",
						"          DepartmentID as string,",
						"          DateOfJoining as date,",
						"          employeeID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> PayRoll",
						"HR, IT, PayRoll union(byName: true,",
						"     partitionBy('hash', 1))~> union",
						"union sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Union.Dataflow.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/WindowDataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "inputDatasetForAggregation",
								"type": "DatasetReference"
							},
							"name": "employee"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Sinksource",
								"type": "DatasetReference"
							},
							"name": "sink",
							"rejectedDataLinkedService": {
								"referenceName": "AzureBlobStorage1",
								"type": "LinkedServiceReference"
							}
						}
					],
					"transformations": [
						{
							"name": "window"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Name as string,",
						"          DepartmentID as integer,",
						"          DateOfJoining as date,",
						"          employeeID as integer,",
						"          Salary as integer,",
						"          DepartmentName as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> employee",
						"employee window(over(DepartmentName),",
						"     asc(Salary, true),",
						"     AvgSalary = avg(Salary),",
						"     partitionBy('hash', 1)) ~> window",
						"window sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['WindowFunction.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/conditionaldf')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "inputDatasetForAggregation",
								"type": "DatasetReference"
							},
							"name": "Conditionalsplit"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Sinksource",
								"type": "DatasetReference"
							},
							"name": "HRsinkCondionalSplit",
							"rejectedDataLinkedService": {
								"referenceName": "AzureBlobStorage1",
								"type": "LinkedServiceReference"
							}
						},
						{
							"dataset": {
								"referenceName": "Sinksource",
								"type": "DatasetReference"
							},
							"name": "ITsinkCondionalSplit",
							"rejectedDataLinkedService": {
								"referenceName": "AzureBlobStorage1",
								"type": "LinkedServiceReference"
							}
						},
						{
							"dataset": {
								"referenceName": "Sinksource",
								"type": "DatasetReference"
							},
							"name": "PayrollsinkCondionalSplit",
							"rejectedDataLinkedService": {
								"referenceName": "AzureBlobStorage1",
								"type": "LinkedServiceReference"
							}
						},
						{
							"dataset": {
								"referenceName": "Sinksource",
								"type": "DatasetReference"
							},
							"name": "OthersinkCondionalSplit",
							"rejectedDataLinkedService": {
								"referenceName": "AzureBlobStorage1",
								"type": "LinkedServiceReference"
							}
						}
					],
					"transformations": [
						{
							"name": "splitCondition"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Name as string,",
						"          DepartmentID as string,",
						"          DateOfJoining as date,",
						"          employeeID as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> Conditionalsplit",
						"Conditionalsplit split(equals(DepartmentID,'1'),",
						"     equals(DepartmentID,'2'),",
						"     equals(DepartmentID,'3'),",
						"     disjoint: false,",
						"     partitionBy('hash', 1)) ~> splitCondition@(HRemployees, ITemployees, Payrollemployees, otheremployee)",
						"splitCondition@HRemployees sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['ConditionalHR.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> HRsinkCondionalSplit",
						"splitCondition@ITemployees sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['ITCondionalSplit.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> ITsinkCondionalSplit",
						"splitCondition@Payrollemployees sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['PayrollsinkCondionalSplit.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> PayrollsinkCondionalSplit",
						"splitCondition@otheremployee sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['OthersinkCondionalSplit'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> OthersinkCondionalSplit"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow1')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "inputDatasetForAggregation",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Sinksource",
								"type": "DatasetReference"
							},
							"name": "sink1"
						},
						{
							"dataset": {
								"referenceName": "Sinksource",
								"type": "DatasetReference"
							},
							"name": "sink2"
						},
						{
							"dataset": {
								"referenceName": "Sinksource",
								"type": "DatasetReference"
							},
							"name": "sink3"
						}
					],
					"transformations": [
						{
							"name": "Hr"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Name as string,",
						"          DepartmentID as short,",
						"          DateOfJoining as string,",
						"          employeeID as short,",
						"          Salary as short,",
						"          DepartmentName as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> source1",
						"source1 split(DepartmentName == 'HR',",
						"     DepartmentName == 'IT',",
						"     disjoint: false,",
						"     partitionBy('hash', 1)) ~> Hr@(Hr, IT, Other)",
						"Hr@Hr sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1",
						"Hr@IT sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink2",
						"Hr@Other sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink3"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow2')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"folder": {
					"name": "Real Time Scenario Data"
				},
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "inputDatasetForAggregation",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Sinksource",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "filter1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Name as string,",
						"          DepartmentID as string,",
						"          DateOfJoining as string,",
						"          employeeID as string,",
						"          Salary as string,",
						"          DepartmentName as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 filter(toInteger(Salary) > 3000,",
						"     partitionBy('hash', 1)) ~> filter1",
						"filter1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['practice.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		}
	]
}